services:
  vllm:
    image: vllm/vllm-openai:v0.11.0
    container_name: vllm  
    command: >
      serve --config /models/gpt-oss-20b/vllm_config.yaml
    runtime: nvidia                     # required for GPU support
    environment:
      VLLM_ATTENTION_BACKEND: "TRITON_ATTN" 
      TIKTOKEN_RS_CACHE_DIR: "/models/gpt-oss-20b/TIKTOKEN/"
      TIKTOKEN_CACHE_DIR: "/models/gpt-oss-20b/TIKTOKEN/"
      TIKTOKEN_ENCODINGS_BASE: "/models/gpt-oss-20b/TIKTOKEN/"
    ports:
      - "8888:8888"
    volumes:
      - "${HOME}/gpt-oss-20b:/models/gpt-oss-20b"
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/metrics"]
      interval: 10s          # run every 5 seconds
      timeout: 5s           # give each probe 2 s to answer
      retries: 6            # 6 × 5 s = 30 s before considered unhealthy
      start_period: 60s     # give the container a little warm‑up time
  spectrum_server:
    build:
      context: spectrum_server
      dockerfile: Dockerfile
    image: spectrum_server:latest
    container_name: spectrum_server
    command: ["python", "-m", "spectrum_server"]
    env_file:
      - env.example
    ports:
      - 8000:8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 60s
  agent:
    build:
      context: agent
      dockerfile: Dockerfile
    image: agent:latest
    container_name: agent
    command: ["--server"]
    ports:
      - 8001:8001
    env_file:
      - env.example
    volumes:
      - /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt:ro
    depends_on:
      vllm:
        condition: service_healthy
      spectrum_server:
        condition: service_healthy
  mongodb:
    image: mongo:8.0
    ports:
      - 27018:27018      
    command: mongod --port 27018    

